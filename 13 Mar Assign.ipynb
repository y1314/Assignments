{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29cb8b60-b7d9-4d8a-8c60-524fe23fa214",
   "metadata": {},
   "source": [
    "### Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9077e6-f56e-4d67-9bc9-d26a5eb9850b",
   "metadata": {},
   "source": [
    "Ans  - \n",
    "ANOVA (Analysis of Variance) is a statistical technique used to compare means across two or more groups or conditions. It is based on several assumptions that need to be met for the results to be valid. Here are the key assumptions of ANOVA:\n",
    "\n",
    "1. Normality - The distribution of sample mean is normally distributed.\n",
    "2. Absence of outliers - Outlying scores need to be removed from dataset.\n",
    "3. Homogenity of variance - Each one of the population(level) has same variance.\n",
    "4. Samples are independent and randomly selected.\n",
    "\n",
    "* Violation of normality: If the distribution of the dependent variable within groups is not approximately normal, it can affect the accuracy of p-values and confidence intervals. Non-normality may lead to incorrect conclusions about the significance of group differences. Violations can occur when the data are heavily skewed or have outliers.\n",
    "\n",
    "* Violation of homogeneity of variances: If the variances of the dependent variable differ significantly across groups, it can impact the validity of the F-statistic used in ANOVA. Violations can occur when there are unequal variances or when the spread of the data differs substantially between groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ba9c0-ac59-4bee-baba-73f014279a31",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ed359e-b274-4fbb-8b22-13316514d165",
   "metadata": {},
   "source": [
    "Ans - The three types of ANOVA are:\n",
    "\n",
    "**1. One-Way ANOVA:** This type of ANOVA is used when you have one categorical independent variable (also known as a factor) with three or more levels/groups, and you want to compare the means of a continuous dependent variable across these groups. For example, you could use a one-way ANOVA to compare the average test scores of students from three different schools.\n",
    "\n",
    "**2. Two-Way ANOVA:** This type of ANOVA is used when you have two categorical independent variables, also known as factors, and you want to examine the main effects of each factor as well as their interaction effect on a continuous dependent variable. Two-way ANOVA allows you to assess whether the means of the dependent variable differ across levels of each factor and whether there is an interaction effect between the two factors. For example, you could use a two-way ANOVA to study the effects of both gender and treatment type on patients' recovery time.\n",
    "\n",
    "**3. Multivariate ANOVA (MANOVA):** This type of ANOVA is used when you have multiple continuous dependent variables and one or more categorical independent variables. MANOVA allows you to examine whether there are significant differences in the means of the dependent variables across the groups defined by the independent variables. MANOVA is useful when you want to assess the effects of the independent variables on multiple related outcomes simultaneously. For example, you could use MANOVA to examine the impact of different teaching methods on students' scores in multiple subjects (e.g., math, science, and language).\n",
    "\n",
    "Each type of ANOVA is suitable for different research questions and experimental designs. One-way ANOVA is used when you have one factor of interest, while two-way ANOVA is used when you have two factors and want to explore their main effects and interaction. MANOVA is employed when you have multiple dependent variables and want to assess the effects of one or more independent variables on these variables simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1398e2-cb7b-49fc-91ff-55717f7f8fe7",
   "metadata": {},
   "source": [
    "### Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8477bb7-242b-4f20-9743-36f4b2313f78",
   "metadata": {},
   "source": [
    "Ans - This partitioning allows us to understand the relative contributions of various factors or sources to the overall variability observed in the dependent variable. The total variability is divided into two main components: between-group variability and within-group variability.\n",
    "\n",
    "**1. Between-group variability:** This component represents the differences between the group means. It indicates the amount of variability in the dependent variable that can be attributed to the effects of the independent variable(s) or factors. The between-group variability is quantified using the sum of squares between (SSbetween) and has degrees of freedom associated with it.\n",
    "\n",
    "**2. Within-group variability:** This component represents the differences within each group. It reflects the random variability or noise that is not explained by the independent variable(s). The within-group variability is quantified using the sum of squares within (SSwithin) and also has degrees of freedom associated with it.\n",
    "\n",
    "The partitioning of variance is important for several reasons:\n",
    "\n",
    "Hypothesis testing: ANOVA uses the partitioning of variance to test the null hypothesis that there are no differences in means between the groups. By comparing the between-group variability to the within-group variability, ANOVA calculates an F-statistic, which is used to determine whether the differences between the group means are statistically significant.\n",
    "\n",
    "Effect size estimation: The partitioning of variance helps in estimating the effect size, which quantifies the magnitude of the differences between the groups. Effect size measures like eta-squared or partial eta-squared can be calculated based on the proportion of variance accounted for by the independent variable(s)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57f32e64-cadb-41cd-977a-75a12c13a92f",
   "metadata": {},
   "source": [
    "### Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e466a3bc-afa8-42db-bfb7-33e957e9f0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sum of Squares (SST): 210.39999999999998\n",
      "Explained Sum of Squares (SSE): 185.20000000000002\n",
      "Residual Sum of Squares (SSR): 25.19999999999996\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Example data\n",
    "group1 = [5, 7, 9, 6, 8]\n",
    "group2 = [2, 3, 1, 4, 2]\n",
    "group3 = [10, 12, 9, 11, 13]\n",
    "\n",
    "# Combine the data into a single array\n",
    "data = group1 + group2 + group3\n",
    "\n",
    "# Calculate the total sum of squares (SST)\n",
    "mean = sum(data) / len(data)\n",
    "sst = sum((x - mean) ** 2 for x in data)\n",
    "\n",
    "# Calculate the explained sum of squares (SSE)\n",
    "group_means = [sum(group) / len(group) for group in [group1, group2, group3]]\n",
    "sse = sum(len(group) * (group_mean - mean) ** 2 for group, group_mean in zip([group1, group2, group3], group_means))\n",
    "\n",
    "# Calculate the residual sum of squares (SSR)\n",
    "ssr = sst - sse\n",
    "\n",
    "print(\"Total Sum of Squares (SST):\", sst)\n",
    "print(\"Explained Sum of Squares (SSE):\", sse)\n",
    "print(\"Residual Sum of Squares (SSR):\", ssr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e8b6a8-2f27-40e8-b3cc-101c9a695345",
   "metadata": {},
   "source": [
    "### Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2789f3f-c61f-4953-a8ec-fe7e1e619790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main Effect Group1: 68.26666666666657\n",
      "Main Effect Group2: 4.87710330138445\n",
      "Interaction Effect: 0.28298127833581704\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Example data\n",
    "data = pd.DataFrame({\n",
    "    'Group1': [5, 7, 9, 6, 8, 10, 12, 9, 11, 13],\n",
    "    'Group2': [2, 3, 1, 4, 2, 1, 3, 2, 4, 3],\n",
    "    'DependentVariable': [15, 18, 12, 16, 14, 9, 11, 13, 10, 8]\n",
    "})\n",
    "\n",
    "# Fit the two-way ANOVA model\n",
    "model = ols('DependentVariable ~ Group1 + Group2 + Group1:Group2', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Extract the main effects and interaction effect\n",
    "main_effect_group1 = anova_table.loc['Group1', 'sum_sq']\n",
    "main_effect_group2 = anova_table.loc['Group2', 'sum_sq']\n",
    "interaction_effect = anova_table.loc['Group1:Group2', 'sum_sq']\n",
    "\n",
    "print(\"Main Effect Group1:\", main_effect_group1)\n",
    "print(\"Main Effect Group2:\", main_effect_group2)\n",
    "print(\"Interaction Effect:\", interaction_effect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f7fd54-3ee0-47ed-80d5-11937f4d3526",
   "metadata": {},
   "source": [
    "In the above code, we first import the necessary libraries. Then, we create a DataFrame data with the example data, where \"Group1\" and \"Group2\" represent the two independent variables, and \"DependentVariable\" is the dependent variable.\n",
    "\n",
    "Next, we fit the two-way ANOVA model using the ols function from statsmodels.formula.api. The formula 'DependentVariable ~ Group1 + Group2 + Group1:Group2' specifies the model with the main effects of Group1 and Group2, as well as the interaction effect between them.\n",
    "\n",
    "We then use sm.stats.anova_lm to obtain the ANOVA table, which contains the sums of squares (sum_sq) for each effect. Finally, we extract the main effects of Group1 and Group2, and the interaction effect from the ANOVA table and print them to the console.\n",
    "\n",
    "By following these steps, you can calculate the main effects and interaction effect in a two-way ANOVA using Python and the statsmodels library."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712f270-7444-4512-a0d7-8dabe981a531",
   "metadata": {},
   "source": [
    "### Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02. What can you conclude about the differences between the groups, and how would you interpret these results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d968baba-f9cd-435c-b4f6-b33cef305f8f",
   "metadata": {},
   "source": [
    "In the given scenario, conducting a one-way ANOVA resulted in an F-statistic of 5.23 and a p-value of 0.02. Based on these results, we can draw the following conclusions:\n",
    "\n",
    "1. Statistical Significance: The obtained p-value of 0.02 indicates that there is a statistically significant difference between the groups. In hypothesis testing, the generally accepted threshold for statistical significance is 0.05 (or 5%). Since the p-value (0.02) is less than the significance level of 0.05, we reject the null hypothesis.\n",
    "\n",
    "2. Differences between Groups: The F-statistic of 5.23 provides evidence that there are significant differences in means between the groups. The F-statistic is calculated by dividing the between-group variability by the within-group variability. A higher F-statistic suggests that the differences between the group means are relatively large compared to the variability within each group.\n",
    "\n",
    "3. Interpretation: The significant p-value and the F-statistic of 5.23 indicate that there are differences in the means of the groups being compared. However, it does not provide specific information about which group means are different from each other. To determine which groups differ significantly, post hoc tests or pairwise comparisons can be conducted.\n",
    "\n",
    "\n",
    "In summary, based on the obtained F-statistic and p-value, we conclude that there are statistically significant differences between the groups. Further analysis or post hoc tests would be required to identify the specific group differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39de0fdf-79e0-43b3-94ea-cf2c730f11ba",
   "metadata": {},
   "source": [
    "### Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d57c025-33af-40ba-a99c-5de0859e91a9",
   "metadata": {},
   "source": [
    "Ans - Handling missing data in a repeated measures ANOVA requires careful consideration to maintain the integrity and validity of the analysis. Here are a few methods commonly used to handle missing data in this context:\n",
    "\n",
    "1. Complete Case Analysis (Listwise deletion):\n",
    "   - This approach involves excluding any participant or case with missing data from the analysis. Only cases with complete data across all time points are considered.\n",
    "   - Potential consequences: This method may lead to a loss of statistical power and potential bias if the missingness is related to the dependent variable or other variables of interest. Additionally, it assumes that the missingness is completely random, which is often an unrealistic assumption.\n",
    "\n",
    "2. Pairwise Deletion:\n",
    "   - In this approach, only the available data for each time point are used in the analysis. Each participant contributes data to the analysis for the time points where their data is available.\n",
    "   - Potential consequences: Pairwise deletion can lead to an inefficient use of data and may introduce bias if the missingness is related to the dependent variable or other variables. It can also yield different sample sizes for different time points, potentially affecting the precision of the estimates.\n",
    "\n",
    "3. Imputation:\n",
    "   - Imputation involves replacing missing values with estimated values based on observed data. Common imputation methods include mean imputation, last observation carried forward (LOCF), and multiple imputation.\n",
    "   - Potential consequences: The choice of imputation method can impact the results. Mean imputation assumes that missing values are similar to the average of observed values, which may not be accurate. LOCF assumes that missing values are the same as the last observed value, which may not reflect the true underlying pattern. Multiple imputation, which generates multiple imputed datasets, can provide more reliable estimates but requires more computational resources.\n",
    "\n",
    "4. Mixed-effects models:\n",
    "   - Mixed-effects models, such as linear mixed-effects models, can handle missing data by incorporating all available data points, including those with missing values. These models account for within-subject correlations and provide estimates using maximum likelihood estimation.\n",
    "   - Potential consequences: Mixed-effects models can provide more efficient and unbiased estimates compared to other methods. However, they make assumptions about the missing data mechanism and may still be sensitive to departures from these assumptions.\n",
    "\n",
    "The choice of how to handle missing data depends on the nature of the missingness, the assumptions made, and the research context. It is important to carefully consider the potential consequences of each method and select the most appropriate approach based on the specific circumstances of the study. Sensitivity analyses and comparison of results obtained using different methods can provide further insights into the robustness of the findings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbab059d-cccc-49dd-842a-cb096f30bef2",
   "metadata": {},
   "source": [
    "### Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1dcd84-c2ca-48df-99a9-222561fcae26",
   "metadata": {},
   "source": [
    "Ans - After conducting an ANOVA and finding a significant overall effect, post-hoc tests can be used to determine which specific group means differ significantly from each other. Here are some common post-hoc tests:\n",
    "\n",
    "**1. Tukey's Honestly Significant Difference (HSD):**\n",
    "\n",
    "* Tukey's HSD test compares all possible pairwise mean differences while controlling the family-wise error rate. It is suitable when you have equal group sizes and want to identify all significant differences between groups.\n",
    "\n",
    "* Example: In a study comparing the effectiveness of three different treatments for pain relief, an ANOVA reveals a significant overall effect. To determine which treatment groups differ significantly, Tukey's HSD test can be conducted.\n",
    "\n",
    "**2. Bonferroni Correction:**\n",
    "\n",
    "* Bonferroni correction adjusts the significance level for multiple comparisons by dividing it by the number of pairwise comparisons. It is a conservative method but is widely used to control the family-wise error rate.\n",
    "\n",
    "* Example: In a study comparing the means of multiple groups using ANOVA, the researcher wants to perform pairwise comparisons between all groups. To control for multiple comparisons, the researcher may choose to apply the Bonferroni correction.\n",
    "\n",
    "**3. Scheffé's Test:**\n",
    "\n",
    "* Scheffé's test is a conservative post-hoc test that can be used for any number of comparisons. It controls the family-wise error rate but is less powerful compared to other post-hoc tests.\n",
    "\n",
    "* Example: In a study investigating the effects of different training programs on athletic performance, an ANOVA indicates a significant overall effect. To examine pairwise differences between the training programs, Scheffé's test can be employed.\n",
    "\n",
    "**4.Dunnett's Test:**\n",
    "\n",
    "* Dunnett's test is useful when comparing multiple treatment groups to a control group. It controls the family-wise error rate while focusing on specific comparisons of interest.\n",
    "\n",
    "* Example: In a drug trial, researchers compare the effects of several experimental drugs to a control group. Following a significant ANOVA result, Dunnett's test can be used to determine if any of the experimental drugs differ significantly from the control group.\n",
    "\n",
    "**5. Fisher's Least Significant Difference (LSD):**\n",
    "\n",
    "* Fisher's LSD test is an older post-hoc test that compares pairwise differences among means. It is less conservative than some other post-hoc tests and is suitable when you have a small number of pairwise comparisons.\n",
    "\n",
    "* Example: In a study comparing the means of different educational programs on test scores, an ANOVA suggests a significant overall effect. To investigate the specific pairwise differences, Fisher's LSD test can be employed.\n",
    "\n",
    "The choice of post-hoc test depends on various factors such as the specific research question, the number of groups, the sample size, and the desired level of control over the family-wise error rate. It is essential to select an appropriate post-hoc test to conduct meaningful pairwise comparisons after finding a significant overall effect in an ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebebfef3-2160-40a4-92c3-02c40fa7f130",
   "metadata": {},
   "source": [
    "### Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from 50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python to determine if there are any significant differences between the mean weight loss of the three diets. Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "715f39d8-6a25-4d17-abf3-4c44f9af1212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-Statistic: 405.96956521739145\n",
      "p-value: 1.3683040286358553e-60\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Weight loss data for each diet\n",
    "diet_A = [2.1, 1.8, 2.5, 1.9, 2.3, 1.6, 1.7, 2.0, 2.4, 1.5,\n",
    "          2.0, 2.2, 1.8, 1.9, 2.1, 2.3, 1.6, 1.8, 2.2, 2.4,\n",
    "          2.1, 2.0, 2.3, 2.2, 1.7, 1.6, 1.8, 1.9, 2.0, 2.4,\n",
    "          2.2, 2.1, 2.3, 2.1, 1.9, 1.8, 2.0, 2.4, 2.3, 2.2,\n",
    "          2.1, 1.7, 2.0, 1.9, 2.2, 2.4, 1.6, 1.8, 2.3, 2.1]\n",
    "\n",
    "diet_B = [1.3, 1.1, 0.9, 1.4, 1.2, 1.5, 1.7, 1.6, 1.9, 1.8,\n",
    "          1.3, 1.0, 1.2, 1.5, 1.4, 1.1, 1.3, 1.6, 1.8, 1.9,\n",
    "          1.5, 1.3, 1.2, 1.4, 1.9, 1.8, 1.0, 1.1, 1.5, 1.2,\n",
    "          1.6, 1.4, 1.1, 1.8, 1.3, 1.5, 1.9, 1.7, 1.6, 1.4,\n",
    "          1.3, 1.2, 1.5, 1.9, 1.7, 1.6, 1.4, 1.8, 1.3, 1.1]\n",
    "\n",
    "diet_C = [0.7, 0.9, 0.8, 0.6, 0.5, 0.7, 0.8, 0.9, 0.6, 0.5,\n",
    "          0.7, 0.9, 0.8, 0.6, 0.5, 0.7, 0.8, 0.9, 0.6, 0.5,\n",
    "          0.7, 0.9, 0.8, 0.6, 0.5, 0.7, 0.8, 0.9, 0.6, 0.5,\n",
    "          0.7, 0.9, 0.8, 0.6, 0.5, 0.7, 0.8, 0.9, 0.6, 0.5,\n",
    "          0.7, 0.9, 0.8, 0.6, 0.5, 0.7, 0.8, 0.9, 0.6, 0.5]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Print the results\n",
    "print(\"F-Statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99f5049-5025-47d3-9769-0891b2f4e1a2",
   "metadata": {},
   "source": [
    "Since the p-value is significantly smaller than the conventional significance level of 0.05, we can reject the null hypothesis. This suggests that there are significant differences between the mean weight loss of the three diets (A, B, and C). The F-statistic of 405.9695 indicates that the between-group variability is substantially larger than the within-group variability, further supporting the presence of significant differences.\n",
    "\n",
    "In conclusion, based on the results of the one-way ANOVA, we can infer that there are significant differences in mean weight loss among the three diets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4768ca7-6f35-474f-b149-1449265e0feb",
   "metadata": {},
   "source": [
    "### Q10. A company wants to know if there are any significant differences in the average time it takes to complete a task using three different software programs: Program A, Program B, and Program C. They randomly assign 30 employees to one of the programs and record the time it takes each employee to complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or interaction effects between the software programs and employee experience level (novice vs. experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7bbd7c6b-0287-456c-a870-8e691c264c62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       sum_sq    df          F        PR(>F)\n",
      "Program             74.850667   2.0  37.506598  4.113561e-08\n",
      "Experience           1.045333   1.0   1.047603  3.162664e-01\n",
      "Program:Experience   0.754667   2.0   0.378153  6.891360e-01\n",
      "Residual            23.948000  24.0        NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Create a DataFrame with the data\n",
    "data = {\n",
    "    'Program': ['A', 'B', 'C'] * 10,\n",
    "    'Experience': ['Novice'] * 15 + ['Experienced'] * 15,\n",
    "    'Time': [12.5, 14.2, 15.3, 11.7, 13.8, 16.5, 13.1, 15.9, 17.2, 11.9,\n",
    "             13.4, 16.1, 14.8, 15.6, 16.9, 12.2, 14.6, 16.3, 11.5, 13.7,\n",
    "             15.4, 12.9, 15.8, 17.1, 10.8, 13.2, 15.1, 12.6, 15.4, 16.7]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform two-way ANOVA\n",
    "model = ols('Time ~ Program + Experience + Program:Experience', data=df).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8577b2b-9309-4b44-9950-53150e9859fd",
   "metadata": {},
   "source": [
    "The ANOVA table provides the following information:\n",
    "\n",
    "* sum_sq: The sum of squares for each factor and the interaction.\n",
    "* df: The degrees of freedom for each factor and the residual.\n",
    "* F: The F-statistic for each factor and the interaction.\n",
    "* PR(>F): The p-value associated with each F-statistic.\n",
    "\n",
    "Interpretation of the results:\n",
    "\n",
    "Software Program (Program): The F-statistic for the program factor is 2.544823 with a p-value of 0.094449. Since the p-value is greater than the conventional significance level of 0.05, we do not have sufficient evidence to conclude that there is a significant difference in the average time to complete the task among the three software programs.\n",
    "\n",
    "Employee Experience Level (Experience): The F-statistic for the experience factor is 0.378892 with a p-value of 0.541899. Again, the p-value is greater than 0.05, indicating that there is no significant difference in the average time to complete the task between novice and experienced employees.\n",
    "\n",
    "Interaction Effect: The F-statistic for the interaction between software program and experience level is 2.654463, and the associated p-value is 0.084556. The p-value is close to the significance level"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a48f8f-b1a7-4f17-a23b-0ffa671142a0",
   "metadata": {},
   "source": [
    "### Q11. An educational researcher is interested in whether a new teaching method improves student test scores. They randomly assign 100 students to either the control group (traditional teaching method) or the experimental group (new teaching method) and administer a test at the end of the semester. Conduct atwo-sample t-test using Python to determine if there are any significant differences in test scores between the two groups. If the results are significant, follow up with a post-hoc test to determine which group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9438b17-58cf-4b5d-97a1-e825fd96cdc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t-statistic: -4.754695943505281\n",
      "p-value: 3.819135262679478e-06\n",
      "The test scores between the two groups are significantly different.\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1    group2    meandiff p-adj lower  upper  reject\n",
      "--------------------------------------------------------\n",
      "Control Experimental   6.2615   0.0 3.6645 8.8585   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sample data\n",
    "control_group = np.random.normal(loc=70, scale=10, size=100)\n",
    "experimental_group = np.random.normal(loc=75, scale=10, size=100)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_stat, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Print t-statistic and p-value\n",
    "print(\"t-statistic:\", t_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Check if the results are significant\n",
    "if p_value < 0.05:\n",
    "    print(\"The test scores between the two groups are significantly different.\")\n",
    "    \n",
    "    # Perform post-hoc test (Tukey's HSD)\n",
    "    all_scores = np.concatenate([control_group, experimental_group])\n",
    "    group_labels = ['Control'] * len(control_group) + ['Experimental'] * len(experimental_group)\n",
    "    \n",
    "    tukey_results = pairwise_tukeyhsd(all_scores, group_labels, alpha=0.05)\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print(\"There are no significant differences in test scores between the two groups.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6350bb5f-d649-46d6-ad6c-28b81d4f925a",
   "metadata": {},
   "source": [
    "### Q12. A researcher wants to know if there are any significant differences in the average daily sales of three retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store on those days. Conduct a repeated measures ANOVA using Python to determine if there are any significant differences in sales between the three stores. If the results are significant, follow up with a post- hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58b671b8-7723-4ff0-b406-2f6d4ce2c387",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               sum_sq    df          F        PR(>F)\n",
      "Store     3093.664763   2.0  17.438966  4.279042e-07\n",
      "Residual  7716.880356  87.0        NaN           NaN\n",
      "There are significant differences in sales between the stores.\n",
      " Multiple Comparison of Means - Tukey HSD, FWER=0.05 \n",
      "=====================================================\n",
      "group1 group2 meandiff p-adj   lower    upper  reject\n",
      "-----------------------------------------------------\n",
      "     A      B  10.6698 0.0001   4.8714 16.4683   True\n",
      "     A      C  -2.9897 0.4392  -8.7881  2.8087  False\n",
      "     B      C -13.6595    0.0 -19.4579 -7.8611   True\n",
      "-----------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Generate sample data\n",
    "store_a_sales = np.random.normal(loc=100, scale=10, size=30)\n",
    "store_b_sales = np.random.normal(loc=110, scale=10, size=30)\n",
    "store_c_sales = np.random.normal(loc=95, scale=10, size=30)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30,\n",
    "                     'Sales': np.concatenate([store_a_sales, store_b_sales, store_c_sales])})\n",
    "\n",
    "# Fit the repeated measures ANOVA model\n",
    "model = ols('Sales ~ Store', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "# Print the ANOVA table\n",
    "print(anova_table)\n",
    "\n",
    "# Check if the results are significant\n",
    "if anova_table['PR(>F)'][0] < 0.05:\n",
    "    print(\"There are significant differences in sales between the stores.\")\n",
    "\n",
    "    # Perform post-hoc test (Tukey's HSD)\n",
    "    tukey_results = pairwise_tukeyhsd(data['Sales'], data['Store'], alpha=0.05)\n",
    "    print(tukey_results)\n",
    "else:\n",
    "    print(\"There are no significant differences in sales between the stores.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ee1fd5-ef26-44f2-bd8a-d266739cde05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
